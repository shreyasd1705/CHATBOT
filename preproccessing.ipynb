{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmB7XT2FzrJO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "fp = open(\"Sarcasm_tweets.txt\", 'r')\n",
    "id_tweet_map = {}\n",
    "tweet_id_map = {}\n",
    "count = 0\n",
    "for line in fp:\n",
    "  line = line.strip()\n",
    "  tokens = line.split(' ')\n",
    "  if len(tokens) == 1 and tokens[0] != '':\n",
    "    current_id = tokens[0]\n",
    "  elif len(tokens) > 1:\n",
    "    id_tweet_map[current_id] = line\n",
    "\n",
    "import string\n",
    "fp = open(\"Sarcasm_tweet_truth.txt\", 'r')\n",
    "id_truth_map = {}\n",
    "\n",
    "for line in fp:\n",
    "  line = line.strip()\n",
    "  if line == '':\n",
    "    continue\n",
    "  elif line[0] in string.digits:\n",
    "    current_id = line\n",
    "  else:\n",
    "    id_truth_map[current_id] = line\n",
    "\n",
    "id_tweet = pd.DataFrame(id_tweet_map.items(), columns=['tweet_id', 'tweet'])\n",
    "lbl_tweet = pd.DataFrame(id_truth_map.items(), columns=['tweet_id', 'sarcasm'])\n",
    "dataset = pd.merge(id_tweet, lbl_tweet, on='tweet_id')\n",
    "dataset = dataset.replace({'sarcasm': {'YES': 1, 'NO': 0}})\n",
    "\n",
    "tweet_rm=[]\n",
    "for j in range(0,len(dataset)):\n",
    "  tweet_rm.append(dataset['tweet'].iloc[j].replace('#sarcasm','').replace('#irony','').replace('#Irony','').replace('#Sarcasm',''))\n",
    "dataset['tweet'] = tweet_rm\n",
    "\n",
    "\n",
    "\n",
    "## Add pre-processing ##\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "#not needed now\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "def emotize(text):\n",
    "    t1 = emoji.replace_emoji(text,' emoji ')\n",
    "    return t1\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def contraction_map(text):\n",
    "    newstring = text\n",
    "    newstring = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newstring.split(\" \")])\n",
    "    return \"\".join(str(newstring)).strip()\n",
    "\n",
    "def text_preprocess(text, row_dict):\n",
    "  dict_row = row_dict\n",
    "  tknzr = WhitespaceTokenizer()\n",
    "  FLAGS = re.MULTILINE | re.DOTALL\n",
    "  # Different regex parts for smiley faces\n",
    "  eyes = r\"[8:=;]\"\n",
    "  nose = r\"['`\\-]?\"\n",
    "  emoticon_mapping = {\n",
    "    \":)\": \"smile\",\n",
    "    \":(\": \"sad\",\n",
    "    \":D\": \"laugh\",\n",
    "    \":P\": \"tongue\",\n",
    "    \";)\": \"wink\",\n",
    "    \"<3\": \"heart\",\n",
    "    \":/\": \"skeptical\",\n",
    "    \":|\": \"neutral\",\n",
    "    \":O\": \"surprised\",\n",
    "    \":*\": \"kiss\",\n",
    "    \":')\": \"happy tears\",\n",
    "    \":/\": \"unsure\",\n",
    "    \":3\": \"cute\",\n",
    "    \":'(\": \"crying\"\n",
    "    }\n",
    "  slangs_mapping = {\n",
    "      \"RT\":\t\"Retweet\",\n",
    "      \"OH\":\t\"Overheard\",\n",
    "      \"FF\":\t\"Follow Friday\",\n",
    "      \"HT\": \"Heard Through\",\n",
    "      \"MM\":\t\"Music Monday\",\n",
    "      \"DM\":\t\"Direct Message\",\n",
    "      \"Tweetup\":\t\"A real life meetup announced on twitter\",\n",
    "      \"SM\":\t\"Social Media\",\n",
    "      \"SB\":\t\"Small Business\",\n",
    "      \"ICYMI\":\t\"In Case You Missed It\",\n",
    "      \"MRT\":\t\"Modified ReTweet\",\n",
    "      \"MT\":\t\"Modified Tweet\",\n",
    "      \"NTS\":\t\"Note To Self\",\n",
    "      \"NP\":\t\"Now Playing\",\n",
    "      \"CC\":\t\"Carbon Copy\",\n",
    "      'BFFL': 'Best friends for life'\n",
    "  }\n",
    "\n",
    "  # function so code less repetitive\n",
    "  def re_sub(pattern, repl):\n",
    "      return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "  text = emotize(text)\n",
    "\n",
    "  def replace_emoticons(text):\n",
    "    pattern = re.compile(r'(:\\)|:\\(|:D|:P|;\\)|<3)')\n",
    "    return pattern.sub(lambda match: emoticon_mapping[match.group()], text)\n",
    "  text = replace_emoticons(text)\n",
    "\n",
    "  def replace_slangs(text):\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in slangs_mapping.keys()) + r')\\b')\n",
    "    return pattern.sub(lambda x: slangs_mapping[x.group()], text)\n",
    "  text = replace_slangs(text)\n",
    "\n",
    "  text = contraction_map(text)\n",
    "\n",
    "  if dict_row['hashtag']==1:\n",
    "    text = re.sub(r'#', '', text)# segment hastags\n",
    "\n",
    "  if dict_row['userhandles'] == 1:\n",
    "    text = re_sub(r\"@\\w+\", \"user\") #replace username to 'user\n",
    "  else:\n",
    "    text = re_sub(r\"@\\w+\", \" \") #remove username\n",
    "\n",
    "  if dict_row['hyperlinks'] == 1:\n",
    "    text = re_sub(r\"r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"url\")\n",
    "  else:\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"\")\n",
    "\n",
    "  def reduce_elongated_characters(text):\n",
    "    pattern = re.compile(r'(\\w+)(\\W)\\2*')\n",
    "    return pattern.sub(r'\\1\\2', text)\n",
    "  if dict_row['elongated_chararcters']==1:\n",
    "    text = reduce_elongated_characters(text)\n",
    "\n",
    "  def reduce_elongated_words(text):\n",
    "    pattern = re.compile(r'(\\w)(\\1{2,})(\\W*)')\n",
    "    return pattern.sub(r'\\1\\1\\3', text)\n",
    "\n",
    "  def add_intense_before_elongated_words(text):\n",
    "    pattern = re.compile(r'(\\b\\w*(\\w)\\2{2,}\\w*\\b)')\n",
    "    return pattern.sub(r'intense \\1', text)\n",
    "  def intense_elongated_words(text):\n",
    "    text = add_intense_before_elongated_words(text)\n",
    "    pattern = re.compile(r'(\\w)(\\1{2,})(\\W*)')\n",
    "    return pattern.sub(r'\\1\\1\\3', text)\n",
    "\n",
    "  if dict_row['replace_elongated_words'] == 0:\n",
    "    text = reduce_elongated_words(text)\n",
    "  else:\n",
    "    text = intense_elongated_words(text)\n",
    "\n",
    "  alphnumeric_slangs = {\n",
    "    '2nite': 'Tonight',\n",
    "    '4eva': 'Forever',\n",
    "    'L8r': 'Later',\n",
    "    'B4': 'Before',\n",
    "    '2moro': 'Tomorrow',\n",
    "    '2day': 'Today',\n",
    "    'G2g': 'Got to go',\n",
    "    'Gr8': 'Great',\n",
    "    '411': 'Information or news',\n",
    "    '2b': 'To be',\n",
    "    '24/7': 'All the time',\n",
    "    '1derful': 'Wonderful',\n",
    "    '2gether': 'Together',\n",
    "    '4get': 'Forget'\n",
    "    }\n",
    "  def replace_alpha_slangs(text):\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in alphnumeric_slangs.keys()) + r')\\b')\n",
    "    return pattern.sub(lambda x: alphnumeric_slangs[x.group()], text)\n",
    "\n",
    "  if row_dict['alphanumeric_slangs'] == 1:\n",
    "    text = replace_alpha_slangs(text)\n",
    "\n",
    "  def remove_punctuations(text):\n",
    "    pattern = re.compile(r'[^\\w\\s]')\n",
    "    return pattern.sub('', text)\n",
    "  if row_dict['remove_punctuations'] == 1:\n",
    "    text = remove_punctuations(text)\n",
    "\n",
    "  def add_intense_to_uppercase_words(text):\n",
    "    pattern = re.compile(r'\\b([A-Z]+)\\b')\n",
    "    return pattern.sub(r'intense \\1', text)\n",
    "  if row_dict['capitalized_words'] == 1:\n",
    "    text = add_intense_to_uppercase_words(text)\n",
    "\n",
    "  def split_mix_case_words(text):\n",
    "    processed_text = \"\"\n",
    "    prev_char = \"\"\n",
    "    middle_char = \"\"\n",
    "\n",
    "    for char in text:\n",
    "        if char.isupper() and middle_char.islower():\n",
    "            processed_text += \" \"\n",
    "        if prev_char.isupper() and middle_char.isupper() and char.islower():\n",
    "            processed_text = processed_text[:-1]\n",
    "            processed_text += \" \"\n",
    "            processed_text += middle_char\n",
    "        if char.isdigit() and middle_char.islower() and not middle_char.isdigit():\n",
    "            processed_text += \" \"\n",
    "        if char.isupper() and middle_char.isdigit():\n",
    "            processed_text += \" \"\n",
    "        if char.islower() and middle_char.isdigit():\n",
    "            processed_text += \" \"\n",
    "        processed_text += char\n",
    "        prev_char = middle_char\n",
    "        middle_char = char\n",
    "\n",
    "    return processed_text\n",
    "  if row_dict['Split_MixCase'] == 1:\n",
    "    text = split_mix_case_words(text)\n",
    "\n",
    "  def split_mix_script(text):\n",
    "    pattern = re.compile(r'(?<=[a-zA-Z])(?=[^a-zA-Z])|(?<=[^a-zA-Z])(?=[a-zA-Z])')\n",
    "    processed_text = pattern.sub(r' ', text)\n",
    "    return processed_text\n",
    "  if row_dict['Split_MixScript'] == 1:\n",
    "    text = split_mix_script(text)\n",
    "\n",
    "  def replace_recurrent_words(text):\n",
    "    prev_word = \"\"\n",
    "    more_prev_word = \"\"\n",
    "    processed_word = \"\"\n",
    "    words = list(text.split())\n",
    "    new_words = []\n",
    "    intial=0\n",
    "    reccur=0\n",
    "    count=0\n",
    "    while intial < (len(words)-1):\n",
    "      count+=1\n",
    "      if count == 2000:\n",
    "          break\n",
    "      if intial < (len(words)-2):\n",
    "          if words[intial] == words[intial + 1] == words[intial+2] and words[intial]!='user' and words[intial]!='url':\n",
    "              reccur=intial\n",
    "              while reccur < (len(words)-1):\n",
    "                if words[intial] == words[reccur]:\n",
    "                  reccur+=1\n",
    "                else:\n",
    "                  #print(j)\n",
    "                  break\n",
    "              new_words.append(\"intense\")\n",
    "              new_words.append(words[intial])\n",
    "              intial=reccur\n",
    "          else:\n",
    "            new_words.append(words[intial])\n",
    "            intial+=1\n",
    "      else:\n",
    "        new_words.append(words[intial])\n",
    "        #new_words.append(word[intial+1])\n",
    "        intial+=1\n",
    "\n",
    "    if reccur != len(words) - 1:\n",
    "      new_words.append(words[intial])\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "  if row_dict['recurrent_word'] == 1:\n",
    "    text = replace_recurrent_words(text)\n",
    "\n",
    "  #tokens = tknzr(text.lower())\n",
    "  tokens = tknzr.tokenize(text)\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "row_dict={'hashtag':1,\n",
    " 'userhandles':0,\n",
    " 'hyperlinks':1,\n",
    " 'emoji':1,\n",
    " 'emoticons':1,\n",
    " 'word_slangs':1,\n",
    " 'expanding_contraction':1,\n",
    " 'elongated_chararcters':0,\n",
    " 'replace_elongated_words':1,\n",
    " 'alphanumeric_slangs':1,\n",
    " 'remove_punctuations':0,\n",
    " 'capitalized_words':0,\n",
    " 'recurrent_word':0,\n",
    " 'Split_MixCase':1,\n",
    " 'Split_MixScript':1,\n",
    " 'misspled_words':0,\n",
    " 'stopwords_removal':1}\n",
    "\n",
    "for line in range (0,len(dataset)):\n",
    "  sent = dataset['tweet'].iloc[line]\n",
    "  sent = text_preprocess(sent, row_dict) #what to process\n",
    "  dataset.loc[line, 'processed_tweets'] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707214742653,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "ee9xW_Id0J5D",
    "outputId": "e1834e60-a305-4dbc-8401-341e17aeb4d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d2c2a73f-9097-4683-b65b-663b0fe5d407\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>866871160725794816</td>\n",
       "      <td>Triple Talaq par Burbak Kuchh nahi bolega</td>\n",
       "      <td>0</td>\n",
       "      <td>Triple Talaq par Burbak Kuchh nahi bolega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>880356789358743553</td>\n",
       "      <td>Batao ye uss site pr se akki sir ke verdict ni...</td>\n",
       "      <td>1</td>\n",
       "      <td>Batao ye uss site pr se akki sir ke verdict ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>877751493889105920</td>\n",
       "      <td>Hindu baheno par julam bardas nahi hoga @Tripl...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hindu baheno par julam bardas nahi hoga Hindu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901806457871466496</td>\n",
       "      <td>Naa bhai.. aisa nhi hai.. mere handle karne se...</td>\n",
       "      <td>0</td>\n",
       "      <td>Naa bhai .. aisa nhi hai .. mere handle karne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>866264330748219392</td>\n",
       "      <td>#RememberingRajiv aaj agar musalman auraten tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Remembering Rajiv aaj agar musalman auraten tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2c2a73f-9097-4683-b65b-663b0fe5d407')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d2c2a73f-9097-4683-b65b-663b0fe5d407 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d2c2a73f-9097-4683-b65b-663b0fe5d407');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-4fbd0515-b846-477a-8b77-f365d576a9c6\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fbd0515-b846-477a-8b77-f365d576a9c6')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-4fbd0515-b846-477a-8b77-f365d576a9c6 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             tweet_id                                              tweet  \\\n",
       "0  866871160725794816          Triple Talaq par Burbak Kuchh nahi bolega   \n",
       "1  880356789358743553  Batao ye uss site pr se akki sir ke verdict ni...   \n",
       "2  877751493889105920  Hindu baheno par julam bardas nahi hoga @Tripl...   \n",
       "3  901806457871466496  Naa bhai.. aisa nhi hai.. mere handle karne se...   \n",
       "4  866264330748219392  #RememberingRajiv aaj agar musalman auraten tr...   \n",
       "\n",
       "   sarcasm                                   processed_tweets  \n",
       "0        0          Triple Talaq par Burbak Kuchh nahi bolega  \n",
       "1        1  Batao ye uss site pr se akki sir ke verdict ni...  \n",
       "2        0  Hindu baheno par julam bardas nahi hoga Hindu ...  \n",
       "3        0  Naa bhai .. aisa nhi hai .. mere handle karne ...  \n",
       "4        0  Remembering Rajiv aaj agar musalman auraten tr...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707214742654,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "_7EnhRGU0UdE",
    "outputId": "8d4f9659-ae93-4fec-98fe-934db6e47186"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hindu baheno par julam bardas nahi hoga Hindu daram par lago hoga hamari Hindu baheno ki soraksa ke liye'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['processed_tweets'].iloc[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707214742654,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "OPOUt6hR0pmC",
    "outputId": "fbcc99ab-6de9-4617-df9c-c998bec97b21"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hindu baheno par julam bardas nahi hoga @TripleTalaq Hindu daram par lago hoga hamari Hindu baheno ki soraksa ke liye'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tweet'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6651,
     "status": "ok",
     "timestamp": 1707128867303,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "lLOfRZDzzt3j",
    "outputId": "e890a497-2765-42f2-cd55-a64d3d94fb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7295,
     "status": "ok",
     "timestamp": 1707214722276,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "EvtR9qQKzuGm",
    "outputId": "73dfc56e-b416-424e-ff1e-51f0bde9c75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/421.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/421.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4782,
     "status": "ok",
     "timestamp": 1707214727046,
     "user": {
      "displayName": "Dharavath Shreyas 4-Yr B.Tech.: Computer Sci. & Engg., IIT(BHU)",
      "userId": "12994373451490178461"
     },
     "user_tz": -330
    },
    "id": "0BnDOxcuzzLP",
    "outputId": "b5922863-118b-4286-d5f5-4d94a1c32e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[Errno 2] No such file or directory: 'drive/My Drive'\n",
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/My\\ Drive"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWJMZMeP8gHNzmESVJhzcf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
